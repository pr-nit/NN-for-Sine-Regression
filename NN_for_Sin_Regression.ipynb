{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN-for-Sin-Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pr-nit/NN-for-Sine-Regression/blob/main/NN_for_Sin_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQboDaFwapvY"
      },
      "source": [
        "# パターン認識・演習　ニューラルネットワークの基礎\n",
        "下記の点を目的とするニューラルネットワークの演習です。\n",
        "\n",
        "* ニューラルネットワークで回帰問題を解くことを体験する\n",
        "* 回帰において個々のニューロンの出力を基底関数と解釈出来ることを理解する\n",
        "* 初期値に依存して学習結果や結果に至る過程が異なりうることを理解する\n",
        "説明を読み、上から順に各セルの三角形をクリックして実行してください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAfBFYTrg0hz"
      },
      "source": [
        "# 1. 各種モジュールの読み込み\n",
        "下記左の三角形をクリックして実行してください。プログラムの変更は不要です。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUpOr_QcerCj"
      },
      "source": [
        "# Macの問題回避\n",
        "# import os\n",
        "# import platform\n",
        "# if platform.system() == 'Darwin':\n",
        "#     os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers import Dense, Activation, Input\n",
        "from keras import optimizers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xihLsc5mhUoF"
      },
      "source": [
        "# 2. 訓練データの生成\n",
        "訓練用のデータ (x,y)と訓練中の性能評価用のデータ(x_test, y_test)を生成します。訓練用のデータも評価用データもNUM個ずつ生成します。\n",
        "* *x*: 0以上1未満の乱数。 サイズ NUM の配列\n",
        "* *y*: *y* = sin (2π*fx* )\n",
        "\n",
        "下記プログラム中の変数は次のとおり\n",
        "* pi: 円周率\n",
        "* NUM: 訓練データの数・評価用データの数\n",
        "* FREQ: 回帰したい関数は三角関数。その周波数。\n",
        "\n",
        "下記二つのセルを、三角形をクリックすることで上から順に実行してください。\n",
        "2番目の三角形をクリックすると、生成したデータのグラフが表示されます。FREQ=2の場合、2つの波が続くグラフになるはずです。（点が密集して分かりにくいですが、青い点は順序のランダムなNUM個の点です）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUk66OMgerCn"
      },
      "source": [
        "# 訓練データの生成\n",
        "# 円周率　π\n",
        "pi = np.pi\n",
        "# 周波数\n",
        "FREQ = 2.0\n",
        "# 訓練データの数・評価用\n",
        "NUM = 1000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKvAzZ9NerCn"
      },
      "source": [
        "# 学習データの生成\n",
        "x = np.random.rand( NUM )\n",
        "y = np.sin( 2.0*pi*FREQ*x )\n",
        "# 評価データの生成\n",
        "x_test = np.random.rand( NUM )\n",
        "y_test = np.sin( 2.0*pi*FREQ*x_test )\n",
        "# 学習データのグラフの表示（横軸x, 縦軸y)\n",
        "plt.scatter(x,y)\n",
        "plt.title('Training Data')\n",
        "plt.xlabel('Input')\n",
        "plt.ylabel('Output')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxmnLmuAyRh_"
      },
      "source": [
        "# 3. ニューラルネットワークの構築\n",
        "次に、入力→中間層→出力 の3層からなるニューラルネットワークをデザインします。入力xも出力yもスカラなので、入力層のニューロンは1つ、出力層のニューロンの出力も1つです。\n",
        "\n",
        "プログラムの読み方を簡単に解説します。\n",
        "\n",
        "* **model = Sequential():** 層を積み重ねたニューラルネットワークをこれから作る宣言です。\n",
        "* **model.add:**  層を追加します。2層目から順に追加します\n",
        "  * 1層目は2層目を作るときにデザイン出来てしまいます\n",
        "* **Dense:** 全結合の層を追加します。つまり、前の層の全てのニューロンを、いま作る層のニューロン全てと結合させます。\n",
        "  * 引数によりニューロンの数と活性化関数と入力の次元を指定します。\n",
        "  * 2層目はZ_NUM個のニューロンを用意して、それらの活性化関数はtanhにして、前の層の出力は1次元とします。\n",
        "  * 3層目はニューロンは一つで、活性化関数は恒等関数(linear)です。\n",
        "* **optimizers:** 最適化の準備をします。ここではStatistical Gradient Descentを採用します。\n",
        "  * **learning_rate:** 勾配ベクトルに掛ける係数（資料ではε）\n",
        "  * **decay:**Learning rateを学習が進むにつれて小さくするための係数です。学習の初期には大胆に係数を更新して、次第に更新に慎重になるための仕掛けです。\n",
        "* **model.compile:**コスト関数と最適化法を指定します\n",
        "  * **loss='mean_square_error':** 二乗誤差をコストにします。\n",
        "  * **'sgd':** 確率的勾配法で最適化します。\n",
        "\n",
        "下のセルを三角形を上から順にクリックすることで実行してください。最初のセルで、2層目のニューロンの数を指定するための変数Z_NUMを定めます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "el_7r_QG4_he"
      },
      "source": [
        "# 中間層のニューロンの数\n",
        "Z_NUM = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FG8AKK-RerCo"
      },
      "source": [
        "# 層の構築\n",
        "model = Sequential()\n",
        "# 2層目の追加\n",
        "model.add(Dense(Z_NUM, activation = 'tanh', input_dim = 1))\n",
        "# 3層目の追加\n",
        "model.add(Dense(1, activation = 'linear'))\n",
        "# 確率的勾配法のデザイン\n",
        "sgd = optimizers.SGD( learning_rate = 0.01, decay = 1e-6 )\n",
        "# コスト関数(loss関数)と最適化法の指定\n",
        "model.compile( loss = 'mean_squared_error', optimizer = 'sgd' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gszX43dm3klv"
      },
      "source": [
        "# 4. 学習\n",
        "学習を開始します。\n",
        "* **model.fit:** 最適化計算により係数を更新します。\n",
        "  * **epochs:** ニューラルネットワークの重み係数を更新する回数を指定します。全てのデータを1回ずつ使って更新すると1 epochです。\n",
        "  * **batch_size:** 沢山ある学習データのうち、batch_size個のデータのみをランダムに選んで更新に使います。1 epochの更新のためにはバッチの選択と更新を複数回実行しなければいけません。\n",
        "* **model.evaluate:** 学習には使っていないデータにより現状のニューラルネットワークの性能を評価します。\n",
        "* **print(score):** 1pochごとに評価値を印字します。\n",
        "\n",
        "下のセルを、三角形を上から順にクリックすることで実行してください。最初のセルで、パラメータの更新回数を指定するための変数EPOCHを定めます。\n",
        "\n",
        "EPOCH=10000のとき、実行時間は5分から10分程度かかります。気長に待って下さい。ニューラルネットワークの係数の初期値が毎回違うので、学習過程は実行のたびに異なります。lossの値が0.1より小さくなれば「成功」です。lossの下がり方は一様ではなく、途中で急激に下がりだすこともあります。運悪くlossが下がらないこともあります。何度か実行して下さい。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXQT3L706VHP"
      },
      "source": [
        "# パラメータの更新回数の指定\n",
        "EPOCH = 10000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFQJaHGFerCp"
      },
      "source": [
        "###### 学習開始\n",
        "result = model.fit(x, y, epochs=EPOCH, batch_size = 64)\n",
        "score = model.evaluate(x_test, y_test, batch_size=16)\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZWAVxciBv3M"
      },
      "source": [
        "# 5. 学習過程の確認\n",
        "横軸にエポック数、縦軸にコスト関数の値を示すグラフを表示します。多くの人は、ロスの変化が一様ではないことに気付くことになると思います。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewnRPc8yerCp"
      },
      "source": [
        "# Lossの変化の可視化（横軸：エポック、縦軸：コスト関数）\n",
        "plt.plot(range(1, EPOCH+1), result.history['loss'], label=\"LOSS\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('LOSS')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fOEYftRCTi5"
      },
      "source": [
        "# 6. 学習結果の確認\n",
        "学習済みのニューラルネットワークに新しいデータを入力して、出力を確認する\n",
        "* **test_input:** 新規に生成したデータ。0から1まで0.01刻みで値を生成\n",
        "* **model_predict:**学習済みニューラルネットワークによる出力 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5L0dTkQEnH9"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "###### 学習データの描画\n",
        "plt.scatter(x,y, label='training data')\n",
        "\n",
        "###### 新規入力データに対する予測結果の描画\n",
        "test_input = np.arange(0,1,0.01)\n",
        "test_output = model.predict(test_input)\n",
        "test_output.reshape(len(test_output),)\n",
        "plt.scatter(test_input, test_output, label='estimated')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iENdeWd2c84V"
      },
      "source": [
        "# 各ニューロンが獲得した基底関数の表示\n",
        "Z_NUM個のニューロンが獲得した基底関数を色を分けて表示"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgMJ7uh9erCq"
      },
      "source": [
        "###### Visualization\n",
        "# Get Coefficietns\n",
        "a = model.layers[0].get_weights()\n",
        "b = model.layers[1].get_weights()\n",
        "\n",
        "# 関数を表示する定義域\n",
        "u = (np.arange(0,1,0.01))[:,np.newaxis] # column vector\n",
        "# 中間層への入力・重みとの線形演算\n",
        "w = np.dot(u, a[0])+a[1]\n",
        "# 活性化関数 (tanh)\n",
        "v = np.tanh(w)\n",
        "# 各ニューロンの出力の計算\n",
        "out = np.dot(v,b[0])+b[1]\n",
        "# 表示\n",
        "plt.scatter(x,y, label='training data')\n",
        "plt.scatter(u,out, label='estimated')\n",
        "for i in range(Z_NUM):\n",
        "    plt.plot(u,v[:,i], label=i)\n",
        "plt.legend(bbox_to_anchor=(1.05, 0.5, 0.5, .100), \n",
        "           borderaxespad=0.,\n",
        "           ncol=1,\n",
        "           mode=\"expand\")\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}